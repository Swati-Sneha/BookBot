import pandas as pd
import numpy as np
import pickle
import re
import matplotlib.pyplot as plt
from urllib.request import urlopen
from bs4 import BeautifulSoup
from operator import itemgetter
import logging
import sys

sys.stderr = open('book_scraper.txt', 'w')

logging.basicConfig(level=logging.DEBUG,
                    format='%(asctime)s %(name)-12s %(levelname)-8s %(message)s',
                    datefmt='%m-%d %H:%M',
                    filename='temp/book_scraper.log',
                    filemode='a')



def cleanup(obj,replace1,replace2, soup):

	'''function to clean up scraped data and return the cleaned data'''

	obj_cleaned=[]
	for x in soup.findAll('p', attrs={'class': obj}):
		txt=x.text.lstrip().replace(replace1,'').replace(replace2,'')
		obj_cleaned.append(txt)
	return obj_cleaned 

def main(url):

	'''opens url and uses beautiful soup to parse data from the webpage'''
	
	logging.info("fetching data")
	html = urlopen(url)
	soup = BeautifulSoup(html, 'lxml') 
	logging.info("parsed Data")

	'''Data cleanup'''
	
	logging.info("Cleaning data")
	try:
		author_cleaned=cleanup('author','by ','', soup)
		page_cleaned=cleanup('pages',' pages','', soup) 
		genre_cleaned=cleanup('genre','genre : ','', soup)
		rating_cleaned=cleanup('rating','','', soup)
		review_cleaned=cleanup('#reviews',',','No_of_reviews ', soup)
		desc_cleaned=cleanup('description','','', soup)
		isbn_cleaned=cleanup('isbn','ISBN ','', soup)
		votes_cleaned=cleanup('votes',',',' votes', soup)
	except Exception as e:
		logging.info("Error while cleaning data ", e)
		exit(0)
	
	logging.info("All data cleaned")
	
	logging.info("Getting all book names in list")
	
	book_names_cleaned=[]
	try:
		for name in soup.findAll('h3'):
			txt=name.text
			if txt!='Comments':
				book_names_cleaned.append(txt)
	except Exception as e:
		logging.info("Getting error while loading book names ", e)
		exit(0)
	
	logging.info("Got all book names in  the list successfully")
	
	
	logging.info("Comments clean-up starting")
	
	divs = soup.find_all('div', attrs={'class':'row'})
	comments_cleaned = []
	try:
		for div in divs:
			comm=''
			comments = div.findAll('p', attrs={'class':re.compile("c[0-9]+")})
			for comment in comments:
				comm+=(comment.text+"|")
			comments_cleaned.append(comm)
	except Exception as e:
		logging.info("Error while cleaning comments ", e)
	
	logging.info("Got all comments in the list successfully")
	
	'''Data cleanup mpleted.
		Creating a dataframe for the required details and then convert it into dict to json.
	'''

	column_nm=['book_name','author','rating','votes','num_reviews','description','no_of_pages','isbn13','genre','reviews']

	dic={'book_name':book_names_cleaned,'author':author_cleaned,'rating':rating_cleaned,'votes':votes_cleaned,'num_reviews':review_cleaned,'description':desc_cleaned,'no_of_pages':page_cleaned,'isbn13':isbn_cleaned,'genre':genre_cleaned,'reviews':comments_cleaned}

	training_data= pd.DataFrame(dic)
	training_data= training_data[column_nm]

	data_dict = training_data.to_dict('split')['data']
	
	'''converting dict to json with key as genre .
	A book falling in the same genre is appended to the value, otherwise it goes to form a new key, value pair'''
	
	book_dict = {}
	
	try:
		for _data in data_dict:
			if _data[8] in book_dict:
				book_dict[_data[8]].append({
						"name" : _data[0],
						"author": _data[1],
						"isbn" :_data[7],
						"rating" :_data[2]
						 
					})
			else:
				book_dict[_data[8]] = [{
					"name" : _data[0],
					"author": _data[1],
					"isbn" :_data[7],
					"rating" :_data[2]
						
				}]
	except Exception as e:
		logging.info("Error appending book details in json format ", e)
		
	logging.info("JSON structure successfully generated for book details")
			
	'''Dictionary value sorted by rating of the book from highest to lowest'''
			
	for _genres in book_dict.keys():
		book_dict[_genres] = sorted(book_dict[_genres], key=itemgetter('rating'), reverse=True)
			
	'''Writing data to pickle file'''		
	
	logging.info("Writing in pickle file")
	pickle_name="book_data.pkl"
	try:
		with open(pickle_name, 'wb') as handle:
			pickle.dump(book_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)
	except Exception as e:
		logging.info("Error writing pickle file",e)
	logging.info("Pickle file generated by the name %s" %(pickle_name))
		
		
		
if __name__=="__main__":
	main("https://fbookshelf.herokuapp.com")